{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word_embedding_using_keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC12WaAC6ONQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences    # all sentense should have same lenght sentense\n",
        "from tensorflow.keras.models import Sequential\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyaVkzSY6bi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "babff80b-e949-4576-d176-e2fb8513e762"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMUIcBET6R0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
        "               the world have come and invaded us, captured our lands, conquered our minds. \n",
        "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
        "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
        "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
        "               We have not grabbed their land, their culture, \n",
        "               their history and tried to enforce our way of life on them. \n",
        "               Why? Because we respect the freedom of others.That is why my \n",
        "               first vision is that of freedom. I believe that India got its first vision of \n",
        "               this in 1857, when we started the War of Independence. It is this freedom that\n",
        "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
        "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
        "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
        "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
        "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
        "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
        "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
        "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
        "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
        "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
        "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
        "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
        "               I see four milestones in my career\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DrhTlyI6V14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)   # 31 sentences\n",
        "words = nltk.word_tokenize(paragraph)    # 399 words\n",
        "a=len(set(words))                        # 188 unique values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQHsN8AT6d_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first we perfprm one-hot representation using keras\n",
        "voc_size=200  # 188 unique values"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0bjpNHP6hhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7f6b64e3-e445-4a01-f829-7ce1f05c4e76"
      },
      "source": [
        "onehot_repr=[one_hot(words,voc_size)for words in sentences] \n",
        "print(onehot_repr)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[28, 162, 13, 20, 198, 184], [45, 141, 159, 168, 169, 38, 162, 159, 99, 135, 18, 13, 162, 72, 115, 196, 57, 148, 169, 170, 177, 169, 107], [159, 61, 87, 18, 90, 18, 5, 18, 81, 18, 111, 18, 100, 18, 3, 18, 99, 99, 168, 65, 176, 115, 165, 57, 150, 135, 152, 159, 189], [123, 175, 162, 176, 192, 168, 68, 129, 61, 74], [175, 162, 176, 177, 41], [175, 162, 176, 52, 164, 71, 164, 97, 164, 38, 115, 80, 68, 99, 169, 169, 168, 45, 86, 65], [20], [151, 175, 93, 18, 49, 168, 125, 164, 13, 20, 42, 150, 190, 13, 164, 168, 49], [28, 139, 164, 184, 83, 136, 150, 190, 168, 168, 45, 52, 43, 175, 68, 18, 182, 168, 150], [57, 13, 168, 49, 164, 175, 195, 130, 115, 7, 115, 152, 86], [9, 175, 46, 176, 57, 54, 159, 133, 93, 57], [42, 67, 190, 198, 27, 26], [198, 114, 159, 175, 162, 117, 15, 33, 74], [57, 13, 153, 175, 4, 23, 67, 15, 22, 74], [175, 46, 56, 18, 192, 99, 57, 168, 18, 13, 45, 78, 168, 60], [175, 162, 15, 33, 108, 73, 185, 45, 193, 123], [169, 198, 4, 46, 137], [169, 146, 46, 49, 104, 151, 163], [123, 175, 71, 18, 54, 156, 68, 4, 23, 67, 15, 22, 74, 54, 192, 115, 54, 64], [109, 168, 103], [28, 162, 15, 55, 190], [184, 195, 163, 16, 68, 18, 13], [151, 28, 139, 164, 94, 184, 47, 16, 68, 18, 13, 54, 159, 133, 93, 57], [100, 145, 69, 145], [175, 195, 26, 81, 176, 100, 67, 15, 78, 46, 172, 123, 67, 35, 42, 46], [139, 195, 186, 81, 45, 81], [42, 59, 29, 159, 68, 162, 140, 159, 13, 93, 107], [25, 84, 45, 168, 18, 17], [168, 104, 47, 90, 24, 193, 65, 168, 115, 25, 11, 164, 56, 168, 43, 77], [28, 159, 117, 68, 162, 140, 159, 99, 13, 168, 65, 144, 115, 194, 168, 18, 93, 162, 168, 42, 45], [28, 4, 89, 41, 45, 42, 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPj4Q7w-6lEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  using one-hot encoding we replacing words with interger which was input for embedding layer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNgkFLCw6o5r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "321e3b69-854b-4fa3-fb78-22202e1ac5c4"
      },
      "source": [
        "sent_length=30     # max sentense length\n",
        "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length) # one_hot_repe, pre padding applied in front of sentense\n",
        "print(embedded_docs)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0  28 162  13  20 198 184]\n",
            " [  0   0   0   0   0   0   0  45 141 159 168 169  38 162 159  99 135  18\n",
            "   13 162  72 115 196  57 148 169 170 177 169 107]\n",
            " [  0 159  61  87  18  90  18   5  18  81  18 111  18 100  18   3  18  99\n",
            "   99 168  65 176 115 165  57 150 135 152 159 189]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 123 175 162 176 192 168  68 129  61  74]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0 175 162 176 177  41]\n",
            " [  0   0   0   0   0   0   0   0   0   0 175 162 176  52 164  71 164  97\n",
            "  164  38 115  80  68  99 169 169 168  45  86  65]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0  20]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 151 175  93  18  49\n",
            "  168 125 164  13  20  42 150 190  13 164 168  49]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  28 139 164 184  83 136 150\n",
            "  190 168 168  45  52  43 175  68  18 182 168 150]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  57\n",
            "   13 168  49 164 175 195 130 115   7 115 152  86]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   9 175  46 176  57  54 159 133  93  57]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0  42  67 190 198  27  26]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0 198 114 159 175 162 117  15  33  74]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  57  13 153 175   4  23  67  15  22  74]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 175  46\n",
            "   56  18 192  99  57 168  18  13  45  78 168  60]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0 175 162  15  33 108  73 185  45 193 123]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0 169 198   4  46 137]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0 169 146  46  49 104 151 163]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0 123 175  71  18  54 156\n",
            "   68   4  23  67  15  22  74  54 192 115  54  64]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0 109 168 103]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0  28 162  15  55 190]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0 184 195 163  16  68  18  13]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 151  28 139 164\n",
            "   94 184  47  16  68  18  13  54 159 133  93  57]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0 100 145  69 145]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 175 195  26  81\n",
            "  176 100  67  15  78  46 172 123  67  35  42  46]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0 139 195 186  81  45  81]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0  42  59  29 159  68 162 140 159  13  93 107]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0  25  84  45 168  18  17]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 168 104  47  90\n",
            "   24 193  65 168 115  25  11 164  56 168  43  77]\n",
            " [  0   0   0   0   0   0   0   0   0  28 159 117  68 162 140 159  99  13\n",
            "  168  65 144 115 194 168  18  93 162 168  42  45]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0  28   4  89  41  45  42   5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v8OuwoB6xP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim=20   # feature dimension   # as a hyper parameter\n",
        "model=Sequential()    # making sequential model\n",
        "model.add(Embedding(voc_size,dim,input_length=sent_length)) # adding layers we have to give (voc size,dimension,max legth)\n",
        "model.compile('adam','mse')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZcLAQM_62eJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "2d7e71e7-d7a1-4fe7-e4b9-775fca1f1122"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 30, 20)            4000      \n",
            "=================================================================\n",
            "Total params: 4,000\n",
            "Trainable params: 4,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6jG3Tg8643X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3019a483-4c87-4578-99e0-7dfe70f95386"
      },
      "source": [
        "print(embedded_docs[0])   # here size is 30 with padding but actual lenghth of 1st sentense is 6 words only"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0  28 162  13  20 198 184]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlFzIacx67_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c63d4d6c-1e63-494f-c039-c18ab5cfa295"
      },
      "source": [
        "print(model.predict(embedded_docs)[0])   # for every word we representing in 20 dimension\n",
        "                                         # for 1st sentence size is 30*20"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [ 0.02880332 -0.03199299  0.02646741 -0.02713878 -0.01494654  0.00612924\n",
            "   0.00654944 -0.03639193 -0.02758142  0.00287366  0.03238442  0.00577438\n",
            "  -0.02464143 -0.04069576  0.0390605   0.04987418  0.03783355 -0.02634509\n",
            "  -0.0085853   0.02331741]\n",
            " [-0.04850499 -0.0420037  -0.03996022 -0.00731013 -0.01448449  0.00428816\n",
            "  -0.03444433  0.00837276  0.01770907 -0.03334145 -0.00637312 -0.02709188\n",
            "   0.04454884 -0.02582667 -0.01421528 -0.04325172 -0.03676182  0.02210642\n",
            "  -0.03260513 -0.04349371]\n",
            " [ 0.01212338 -0.04819587 -0.02375041 -0.04508951  0.01237946  0.03121947\n",
            "  -0.0484285   0.01213045 -0.036227   -0.01075467 -0.04289981  0.02911701\n",
            "  -0.04149644  0.00760981  0.04572633 -0.01091026  0.04031153 -0.04284936\n",
            "   0.04812871  0.01885332]\n",
            " [-0.00966762 -0.04553923 -0.0127542   0.02593751  0.0210802   0.0389224\n",
            "  -0.04678793  0.02556975  0.03392607  0.01379314  0.00316949 -0.01637847\n",
            "  -0.01522901  0.0416831  -0.0232293  -0.03228321 -0.0033178  -0.01446547\n",
            "   0.04466904  0.01690013]\n",
            " [-0.02593447 -0.0417168  -0.04042851 -0.04919421 -0.03508447  0.03888348\n",
            "  -0.04574051  0.03030105 -0.04827528 -0.01645577 -0.0194023  -0.04339163\n",
            "   0.04953332 -0.02345749  0.01035211  0.03363054  0.01231002  0.02484577\n",
            "  -0.02155856 -0.02247893]\n",
            " [ 0.04191701 -0.00594121 -0.04889319  0.04654186  0.04320064  0.03883112\n",
            "  -0.03278887  0.04382998  0.03768292 -0.01678851  0.01161624 -0.00171461\n",
            "   0.04749442  0.02752921 -0.02502053 -0.01138232  0.01096579  0.03817389\n",
            "  -0.0437555   0.0141824 ]\n",
            " [ 0.02933927 -0.04249411 -0.00949525  0.01637459 -0.02734734  0.03136188\n",
            "   0.02351146  0.00626593 -0.00555497  0.02608266 -0.04368459 -0.03637648\n",
            "  -0.0314281  -0.01469306 -0.04052757  0.03496239  0.02997067  0.03290452\n",
            "   0.00685392 -0.03253444]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}